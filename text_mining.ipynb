{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import bibliotek "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import string\n",
    "import morfeusz2\n",
    "import itertools\n",
    "import operator\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Utworzenie korpusu dokumentÃ³w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No such file or directory: 'c:\\\\Users\\\\s-A013-29.CAMPUS\\\\Desktop\\\\Project\\\\TextMining\\\\literaturar'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m corpus_dir=\u001b[33m\"\u001b[39m\u001b[33m./literaturar\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m corpus = \u001b[43mPlaintextCorpusReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m.*\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43m.txt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m files = corpus.fileids()\n\u001b[32m      4\u001b[39m files\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\s-A013-29.CAMPUS\\Desktop\\Project\\TextMining\\.venv\\Lib\\site-packages\\nltk\\corpus\\reader\\plaintext.py:62\u001b[39m, in \u001b[36mPlaintextCorpusReader.__init__\u001b[39m\u001b[34m(self, root, fileids, word_tokenizer, sent_tokenizer, para_block_reader, encoding)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     38\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     39\u001b[39m     root,\n\u001b[32m   (...)\u001b[39m\u001b[32m     44\u001b[39m     encoding=\u001b[33m\"\u001b[39m\u001b[33mutf8\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     45\u001b[39m ):\n\u001b[32m     46\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     47\u001b[39m \u001b[33;03m    Construct a new plaintext corpus reader for a set of documents\u001b[39;00m\n\u001b[32m     48\u001b[39m \u001b[33;03m    located at the given root directory.  Example usage:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     60\u001b[39m \u001b[33;03m        corpus into paragraph blocks.\u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m     \u001b[43mCorpusReader\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfileids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m     \u001b[38;5;28mself\u001b[39m._word_tokenizer = word_tokenizer\n\u001b[32m     64\u001b[39m     \u001b[38;5;28mself\u001b[39m._sent_tokenizer = sent_tokenizer\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\s-A013-29.CAMPUS\\Desktop\\Project\\TextMining\\.venv\\Lib\\site-packages\\nltk\\corpus\\reader\\api.py:80\u001b[39m, in \u001b[36mCorpusReader.__init__\u001b[39m\u001b[34m(self, root, fileids, encoding, tagset)\u001b[39m\n\u001b[32m     78\u001b[39m         root = ZipFilePathPointer(zipfile, zipentry)\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m         root = \u001b[43mFileSystemPathPointer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(root, PathPointer):\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCorpusReader: expected a string or a PathPointer\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\s-A013-29.CAMPUS\\Desktop\\Project\\TextMining\\.venv\\Lib\\site-packages\\nltk\\data.py:311\u001b[39m, in \u001b[36mFileSystemPathPointer.__init__\u001b[39m\u001b[34m(self, _path)\u001b[39m\n\u001b[32m    309\u001b[39m _path = os.path.abspath(_path)\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(_path):\n\u001b[32m--> \u001b[39m\u001b[32m311\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo such file or directory: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m % _path)\n\u001b[32m    312\u001b[39m \u001b[38;5;28mself\u001b[39m._path = _path\n",
      "\u001b[31mOSError\u001b[39m: No such file or directory: 'c:\\\\Users\\\\s-A013-29.CAMPUS\\\\Desktop\\\\Project\\\\TextMining\\\\literaturar'"
     ]
    }
   ],
   "source": [
    "corpus_dir=\"./literatura\"\n",
    "corpus = PlaintextCorpusReader(corpus_dir, \".*\\.txt\")\n",
    "files = corpus.fileids()\n",
    "files"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
